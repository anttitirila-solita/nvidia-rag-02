services:
  vllm:
    image: vllm/vllm-openai:latest
    runtime: nvidia
    container_name: vllm
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: ["gpu"]
    environment:
      HUGGING_FACE_HUB_TOKEN: ${HUGGING_FACE_HUB_TOKEN}
      HF_TOKEN: ${HUGGING_FACE_HUB_TOKEN}
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    ports:
      - "8001:8000"
    ipc: host
    command: >
      --model google/gemma-3-12b-it

networks:
  default:
    external: true
    name: nvidia-rag
     